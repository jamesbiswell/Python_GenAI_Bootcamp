{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b81cbe97-404f-4172-a162-ab680fd6b9b6",
   "metadata": {},
   "source": [
    "## AI That Thinks: Diving into OpenAIâ€™s Reasoning Models (o1 and o3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf464b1-d719-401d-a361-66dacc43fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade openai -q  # upgrade openai to the latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a5532b-2279-4c21-aee7-017c71a91c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "# loading the OpenAI API key used for authentication\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea2433e-0718-41aa-8f18-4256cb2b4325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "# This script reads a log file where each line is in the format:\n",
      "# \"YYYY-MM-DD HH:MM:SS - LEVEL - Message\"\n",
      "# and prints the count of messages for each log level (e.g., INFO, ERROR, DEBUG).\n",
      "\n",
      "# Check if exactly one argument (the log file) is provided.\n",
      "if [[ $# -ne 1 ]]; then\n",
      "    echo \"Usage: $0 <log_file>\"\n",
      "    exit 1\n",
      "fi\n",
      "\n",
      "LOGFILE=\"$1\"\n",
      "\n",
      "# Check if the provided log file exists and is readable.\n",
      "if [[ ! -f \"$LOGFILE\" ]]; then\n",
      "    echo \"Error: File '$LOGFILE' does not exist.\"\n",
      "    exit 2\n",
      "fi\n",
      "\n",
      "if [[ ! -r \"$LOGFILE\" ]]; then\n",
      "    echo \"Error: File '$LOGFILE' is not readable.\"\n",
      "    exit 3\n",
      "fi\n",
      "\n",
      "# Use awk to parse each line based on \" - \" as the delimiter.\n",
      "# The second field contains the log level.\n",
      "awk -F\" - \" '\n",
      "{\n",
      "    # Check if the line has at least two fields.\n",
      "    if (NF >= 2)\n",
      "        count[$2]++\n",
      "}\n",
      "END {\n",
      "    # Print out the counts for each log level.\n",
      "    for (level in count)\n",
      "        print level \": \" count[level]\n",
      "}\n",
      "' \"$LOGFILE\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write a Bash script that reads a log file where each line is in the format \n",
    "'YYYY-MM-DD HH:MM:SS - LEVEL - Message', and prints out the count of messages for each log level (e.g., INFO, ERROR, DEBUG).\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='o3-mini',  # a smaller, faster reasoning model\n",
    "    reasoning_effort='medium',\n",
    "    max_completion_tokens = 10000,\n",
    "    messages=[\n",
    "        {'role': 'developer', 'content': 'You are an experienced Bash developer and provide the complete Bash script as your solution.'},\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "949d76d6-abf2-4617-8fb3-4b0724e03bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=1102, prompt_tokens=59, total_tokens=1161, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=640, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e0110-5fd6-4678-99aa-c8e7b49eb521",
   "metadata": {},
   "source": [
    "## Best Practices for Prompting Reasoning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e92f1d-8c61-4cfc-a5c5-4c6ec2f6f87e",
   "metadata": {},
   "source": [
    "### 1. Use Developer Messages Instead of System Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1dfe2-880a-4b46-b7ba-35367e12d346",
   "metadata": {},
   "source": [
    "### 2. Keep Prompts Simple and Direct\n",
    "Example:\n",
    "\n",
    "good_prompt='Summarize this research paper in one paragraph.' \n",
    "\n",
    "bad_prompt= 'Think step by step and summarize this research paper while considering the key findings, methods, and implications.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8219bc8-c22b-4357-8bd1-d2377e8b7e82",
   "metadata": {},
   "source": [
    "### 3. Avoid Chain-of-Thought Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f8c9eb-0522-4fea-b30a-fa8b63986fee",
   "metadata": {},
   "source": [
    "### 4. Use Delimiters for Clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052183ea-fa73-494f-a6fd-8b4055b6af34",
   "metadata": {},
   "source": [
    "### 5. Start with Zero-Shot, Then Use Few-Shot If Needed\n",
    "[INPUT]: 'Describe an AI breakthrough in under 50 words.'\n",
    "\n",
    "[EXAMPLE]: 'GPT-4o optimized efficiency and reduced latency, improving real-time interactions.'\n",
    "\n",
    "[YOUR TURN]:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1b09f6-3c1f-42a3-83e8-30d2a935166d",
   "metadata": {},
   "source": [
    "### 6. Provide Specific Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15c860-4f58-4865-84ce-d0ce3729d257",
   "metadata": {},
   "source": [
    "### 7. Be Clear About Your End Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4ec38-b86e-4468-8e8d-9f2ff0eaa65f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
