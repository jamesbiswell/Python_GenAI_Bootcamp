from preprocess_data import clean_text, tokenize_text

# Sample text to process
new_text = 'Building GenAI pipelines is fun!'
print(clean_text(new_text))
print(tokenize_text(new_text))
